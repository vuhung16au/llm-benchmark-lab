# llm-benchmark-lab
This repository provides an advanced benchmarking tool for evaluating large language models (LLMs) running on Ollama. It measures model performance (tokens per second), system resource usage (CPU, memory, GPU), and generates detailed reports. Ideal for comparing LLMs on your local machine with reproducible metrics and automated reporting.
